# DevSavvy Chatbot Recreation Architecture
**Version 2.0 - Professional Reference Guide**

This documentation outlines the complete engineering process to recreate the DevSavvy Chatbot ecosystem. The architecture consists of a high-performance React frontend hosted locally and a powerful LLM backend running on Google Colab, bridged via a secure Ngrok tunnel.

---

## 1. System Architecture

*   **Frontend**: React (Vite) + Tailwind CSS
    *   *Role*: User Interface, State Management, Stream Rendering.
    *   *Location*: Local Machine.
*   **Backend**: Ollama (Llama 3.2 or equivalent)
    *   *Role*: Large Language Model Inference.
    *   *Location*: Google Colab (Cloud GPU).
*   **Bridge**: Ngrok
    *   *Role*: Secure tunneling to expose the Colab local server to the public internet.

---

## 2. Backend Initialization (Google Colab)

Before interacting with the frontend, the backend must be active.

1.  **Environment Setup**:
    *   Open your Google Colab notebook.
    *   Ensure the runtime type is set to **T4 GPU** (or better) for optimal inference speed.

2.  **Execution Sequence**:
    *   Install dependencies: `ollama`, `pyngrok`.
    *   Initialize the Ollama server in the background.
    *   Pull the desired model (e.g., `ollama pull llama3.2`).
    *   **Critical**: Establish the Ngrok tunnel to port `11434`.

3.  **Output Retrieval**:
    *   Locate the public Ngrok URL generated by the script (e.g., `https://example-id.ngrok-free.app`).
    *   *Note: Keep this tab open. The tunnel must remain active for the frontend to connect.*

---

## 3. Frontend Development (Local Environment)

### Step 3.1: Project Initialization

Execute the following commands in your local terminal to scaffold the application using Vite.

```bash
# 1. Create a new React application using Vite
npm create vite@latest devsavvy-react -- --template react

# 2. Navigate into the project directory
cd devsavvy-react

# 3. Install core dependencies
npm install

# 4. Install styling and utility libraries
npm install -D tailwindcss postcss autoprefixer
npx tailwindcss init -p

# 5. Install icon and markdown rendering libraries
npm install lucide-react react-markdown
```

### Step 3.2: Configuration

**File**: `tailwind.config.js`
Configure the design system tokens.

```javascript
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {
      colors: {
        primary: '#7c3aed',
        secondary: '#6366f1',
        dark: '#0f172a',
        surface: '#1e293b',
      },
      fontFamily: {
        sans: ['Inter', 'system-ui', 'sans-serif'],
      }
    },
  },
  plugins: [],
}
```

**File**: `src/index.css`
Establish the global styles and base theme.

```css
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

@tailwind base;
@tailwind components;
@tailwind utilities;

:root {
  --app-bg: #0f172a;
}

body {
  background-color: var(--app-bg);
  color: #f8fafc;
  font-family: 'Inter', sans-serif;
  margin: 0;
  -webkit-font-smoothing: antialiased;
}

/* Custom Scrollbar for a premium feel */
::-webkit-scrollbar {
  width: 6px;
}
::-webkit-scrollbar-track {
  background: transparent;
}
::-webkit-scrollbar-thumb {
  background: #334155;
  border-radius: 10px;
}
::-webkit-scrollbar-thumb:hover {
  background: #475569;
}
```

---

## 4. Implementation

**File**: `src/App.jsx`
The core application logic handling API communication, state, and UI rendering.

**Important**: You must update the `OLLAMA_BASE_URL` constant with your active Ngrok link from Colab.

```jsx
import React, { useState, useRef, useEffect } from 'react';
import { Send, Download, Save, PlusCircle, MessageSquare, Menu, Bot, User, Trash2 } from 'lucide-react';
import ReactMarkdown from 'react-markdown';

// --- CONFIGURATION ---
// ⚠️ REPLACE WITH YOUR CURRENT NGROK URL FROM GOOGLE COLAB ⚠️
const OLLAMA_BASE_URL = "https://your-ngrok-url.ngrok-free.app"; 
const MODEL_NAME = "llama3.2"; // Ensure this model is pulled in Colab

function App() {
  const [messages, setMessages] = useState([
    { role: 'assistant', content: "Hello! I am DevSavvy, your AI assistant running on Google Colab. How can I help you today?" }
  ]);
  const [input, setInput] = useState("");
  const [isLoading, setIsLoading] = useState(false);
  const [showSidebar, setShowSidebar] = useState(true);
  const messagesEndRef = useRef(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const handleSend = async () => {
    if (!input.trim()) return;

    const userMsg = { role: 'user', content: input };
    setMessages(prev => [...prev, userMsg]);
    setInput("");
    setIsLoading(true);

    try {
      // API Call to Google Colab via Ngrok
      // Note: We check for the trailing slash to ensure valid URL construction
      const baseUrl = OLLAMA_BASE_URL.endsWith('/') ? OLLAMA_BASE_URL.slice(0, -1) : OLLAMA_BASE_URL;
      
      const response = await fetch(`${baseUrl}/api/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          // Critical header to bypass Ngrok's browser warning webpage
          'ngrok-skip-browser-warning': 'true' 
        },
        body: JSON.stringify({
          model: MODEL_NAME,
          messages: [...messages, userMsg],
          stream: false 
        })
      });

      if (!response.ok) {
        throw new Error(`API Error: ${response.statusText}`);
      }

      const data = await response.json();
      
      if (data.message) {
        setMessages(prev => [...prev, data.message]);
      } else {
        throw new Error("Invalid response format from Ollama");
      }

    } catch (error) {
      console.error("Connection Error:", error);
      setMessages(prev => [...prev, { 
        role: 'assistant', 
        content: `**Connection Error**: Could not reach the Ollama backend.\n\n` +
                 `- Check if your Google Colab instance is running.\n` +
                 `- Verify the Ngrok URL in \`src/App.jsx\` matches your Colab output.\n` +
                 `- Error details: *${error.message}*`
      }]);
    } finally {
      setIsLoading(false);
    }
  };

  const handleDownload = () => {
    const text = messages.map(m => `[${m.role.toUpperCase()}]\n${m.content}\n`).join('\n-------------------\n');
    const blob = new Blob([text], { type: 'text/plain' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `devsavvy-chat-${new Date().toISOString().slice(0,10)}.txt`;
    a.click();
  };

  return (
    <div className="flex h-screen bg-[#0f172a] text-white overflow-hidden font-sans">
      
      {/* SIDEBAR NAVIGATION */}
      <div className={`${showSidebar ? 'w-80' : 'w-0'} transition-all duration-300 ease-in-out border-r border-white/5 bg-[#1e293b]/50 backdrop-blur-xl flex flex-col relative`}>
        <div className="p-6 border-b border-white/5">
           <h1 className="text-xl font-bold bg-gradient-to-r from-indigo-400 to-cyan-400 bg-clip-text text-transparent">
            DevSavvy
          </h1>
          <p className="text-xs text-slate-400 mt-1">Professional AI Assistant</p>
        </div>
        
        <div className="p-4 space-y-3 flex-1 overflow-y-auto">
          <div className="bg-indigo-500/10 border border-indigo-500/20 rounded-lg p-3">
             <div className="flex items-center gap-2 text-indigo-300 text-sm font-medium">
                <div className="w-2 h-2 rounded-full bg-green-400 animate-pulse"></div>
                Colab Backend Active
             </div>
             <p className="text-xs text-indigo-400/60 mt-1 pl-4">Model: {MODEL_NAME}</p>
          </div>

          <button onClick={() => setMessages([])} className="w-full flex items-center gap-3 bg-white/5 hover:bg-white/10 p-3 rounded-lg transition-colors text-sm font-medium text-slate-300">
            <PlusCircle size={18} className="text-indigo-400" /> New Chat
          </button>
          
          <button onClick={handleDownload} className="w-full flex items-center gap-3 bg-white/5 hover:bg-white/10 p-3 rounded-lg transition-colors text-sm font-medium text-slate-300">
            <Download size={18} className="text-emerald-400" /> Export History
          </button>
        </div>

        <div className="p-4 border-t border-white/5">
             <div className="text-xs text-slate-500 text-center">Version 2.0 • Powered by Llama</div>
        </div>
      </div>

      {/* MAIN INTERFACE */}
      <div className="flex-1 flex flex-col h-full relative bg-gradient-to-br from-[#0f172a] to-[#1e1b4b]">
        
        {/* HEADER */}
        <div className="h-16 border-b border-white/5 flex items-center justify-between px-6 bg-[#0f172a]/80 backdrop-blur-md z-10">
          <button onClick={() => setShowSidebar(!showSidebar)} className="p-2 hover:bg-white/10 rounded-lg transition-colors">
            <Menu size={20} className="text-slate-400" />
          </button>
          <div className="flex items-center gap-2">
             <span className="text-sm font-medium text-slate-400">Connected to:</span>
             <span className="text-xs bg-indigo-500/20 text-indigo-300 px-2 py-1 rounded border border-indigo-500/20 font-mono">
                {OLLAMA_BASE_URL.split('//')[1]?.split('.')[0] || 'Unknown'}
             </span>
          </div>
        </div>

        {/* CHAT AREA */}
        <div className="flex-1 overflow-y-auto p-4 sm:p-6 space-y-6 scroll-smooth">
          {messages.map((msg, idx) => (
            <div key={idx} className={`flex gap-4 max-w-4xl mx-auto ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}>
              
              {/* Avatar Assistant */}
              {msg.role === 'assistant' && (
                <div className="w-8 h-8 rounded-lg bg-indigo-600 flex items-center justify-center flex-shrink-0 mt-1 shadow-lg shadow-indigo-500/20">
                  <Bot size={18} className="text-white" />
                </div>
              )}

              {/* Message Bubble */}
              <div className={`
                max-w-[85%] md:max-w-[75%] p-4 rounded-2xl text-sm leading-relaxed shadow-lg
                ${msg.role === 'user' 
                  ? 'bg-gradient-to-br from-indigo-600 to-violet-600 text-white rounded-br-none' 
                  : 'bg-[#1e293b] border border-white/5 text-slate-200 rounded-bl-none'}
              `}>
                {msg.role === 'assistant' ? (
                   <ReactMarkdown 
                    className="prose prose-invert prose-sm max-w-none prose-p:leading-6 prose-pre:bg-[#0f172a] prose-pre:border prose-pre:border-white/10"
                   >
                     {msg.content}
                   </ReactMarkdown>
                ) : (
                  <div>{msg.content}</div>
                )}
              </div>

              {/* Avatar User */}
              {msg.role === 'user' && (
                <div className="w-8 h-8 rounded-lg bg-slate-700 flex items-center justify-center flex-shrink-0 mt-1">
                  <User size={18} className="text-slate-300" />
                </div>
              )}
            </div>
          ))}
          
          {isLoading && (
             <div className="flex gap-4 max-w-4xl mx-auto">
                <div className="w-8 h-8 rounded-lg bg-indigo-600 flex items-center justify-center flex-shrink-0 shadow-lg shadow-indigo-500/20">
                   <div className="w-4 h-4 border-2 border-white/30 border-t-white rounded-full animate-spin"></div>
                </div>
                <div className="bg-[#1e293b] border border-white/5 px-4 py-3 rounded-2xl rounded-bl-none text-sm text-slate-400 animate-pulse">
                   Processing request...
                </div>
             </div>
          )}
          <div ref={messagesEndRef} />
        </div>

        {/* INPUT AREA */}
        <div className="p-4 bg-[#0f172a]/90 backdrop-blur-lg border-t border-white/5">
          <div className="max-w-4xl mx-auto relative">
            <input
              type="text"
              value={input}
              onChange={(e) => setInput(e.target.value)}
              onKeyDown={(e) => e.key === 'Enter' && handleSend()}
              placeholder="Message DevSavvy..."
              className="w-full bg-[#1e293b] text-slate-200 border border-white/10 rounded-xl px-4 py-4 pr-12 focus:outline-none focus:border-indigo-500/50 focus:ring-1 focus:ring-indigo-500/50 transition-all placeholder-slate-500"
            />
            <button 
              onClick={handleSend}
              disabled={isLoading || !input.trim()}
              className="absolute right-3 top-3 p-2 bg-indigo-600 hover:bg-indigo-500 rounded-lg text-white transition-all disabled:opacity-50 disabled:cursor-not-allowed"
            >
              <Send size={18} />
            </button>
          </div>
          <div className="text-center mt-2">
            <p className="text-[10px] text-slate-600">
              AI can make mistakes. Please verify important information.
            </p>
          </div>
        </div>

      </div>
    </div>
  );
}

export default App;
```

---

## 5. Usage Instructions

1.  **Start Background Services**: Ensure your Google Colab instance is running and Ngrok is active.
2.  **Update URL**: Copy the **https** link from Colab and paste it into `OLLAMA_BASE_URL` in `src/App.jsx`.
3.  **Launch Frontend**:
    ```bash
    npm run dev
    ```
4.  **Verification**:
    *   Open your browser to the localhost URL provided by Vite.
    *   Send a "Hello" message.
    *   If you see the response from the model, your end-to-end pipeline is fully operational.
